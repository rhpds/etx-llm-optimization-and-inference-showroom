:imagesdir: ../assets/images
[#deploy-intro]
= Module 1: LLM Deployment Strategies

== Introduction

This module covers deploying Red Hat Inference Server (vLLM).

## Deployment Targets

**OpenShift AI**: Managed AI platform providing MLOps capabilities, data science workflows, and enterprise governance. Optimal for integrated AI pipelines and managed model serving.

## Learning Objectives

- Deploy vLLM on OpenShift AI
- Establish foundation for performance evaluation and optimization

## Prerequisites

- Access to target deployment environment
- Basic familiarity with containers and Kubernetes concepts
- Understanding of LLM serving requirements

Ready to deploy? Let's start with platform-specific implementations.
